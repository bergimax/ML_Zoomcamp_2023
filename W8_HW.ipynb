{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f903176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "809819c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING MODEL CREATION:\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0cf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILING THE MODEL:\n",
    "model.compile(loss='binary_crossentropy',\\\n",
    "             optimizer=optimizers.SGD(learning_rate=0.002, momentum=0.8),\\\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebbb70",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af86e3",
   "metadata": {},
   "source": [
    "binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67242711",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e855870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#SUMMARY:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee21f67e",
   "metadata": {},
   "source": [
    "11215873 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5491591",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c936e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "train_dir = './data/train'\n",
    "test_dir = './data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f672617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING IMAGE DATAGENERATOR:\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f1ddb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATAGENERATOR:\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fb0410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#@ VALIDATION DATAGENERATOR:\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(150, 150),\n",
    "                                                  batch_size=20,\n",
    "                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "791d0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 18s 98ms/step - loss: 0.6829 - acc: 0.5575 - val_loss: 0.6494 - val_acc: 0.5458\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 19s 104ms/step - loss: 0.6271 - acc: 0.6462 - val_loss: 0.6327 - val_acc: 0.5621\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 18s 96ms/step - loss: 0.5772 - acc: 0.7006 - val_loss: 0.5490 - val_acc: 0.7429\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 17s 94ms/step - loss: 0.5303 - acc: 0.7449 - val_loss: 0.5512 - val_acc: 0.6950\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 17s 93ms/step - loss: 0.5114 - acc: 0.7629 - val_loss: 0.5194 - val_acc: 0.7505\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 18s 97ms/step - loss: 0.4810 - acc: 0.7745 - val_loss: 0.5589 - val_acc: 0.7081\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 19s 102ms/step - loss: 0.4570 - acc: 0.7958 - val_loss: 0.5092 - val_acc: 0.7603\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 19s 103ms/step - loss: 0.4346 - acc: 0.8123 - val_loss: 0.4911 - val_acc: 0.7767\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 20s 111ms/step - loss: 0.4057 - acc: 0.8303 - val_loss: 0.5215 - val_acc: 0.7364\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.3835 - acc: 0.8401 - val_loss: 0.5592 - val_acc: 0.7429\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "778b34d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7686973214149475"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MEDIAN OF ACCURACY:\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc_median = np.median(acc)\n",
    "acc_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3348b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09206242536749262"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STANDARD DEVIATION OF LOSS:\n",
    "loss_std = np.std(loss)\n",
    "loss_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa8f3f",
   "metadata": {},
   "source": [
    "#  Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03a76300",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc0b46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75fa7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72da60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150, 150), \n",
    "                                                    batch_size=20, \n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b344b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4d47369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 31s 171ms/step - loss: 0.4973 - acc: 0.7658 - val_loss: 0.5020 - val_acc: 0.7723\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 35s 189ms/step - loss: 0.4882 - acc: 0.7764 - val_loss: 0.4978 - val_acc: 0.7767\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 39s 212ms/step - loss: 0.4828 - acc: 0.7813 - val_loss: 0.4901 - val_acc: 0.7625\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 39s 214ms/step - loss: 0.4716 - acc: 0.7767 - val_loss: 0.4923 - val_acc: 0.7636\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.4730 - acc: 0.7811 - val_loss: 0.4625 - val_acc: 0.7908\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.4711 - acc: 0.7841 - val_loss: 0.4700 - val_acc: 0.8050\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 39s 211ms/step - loss: 0.4628 - acc: 0.7892 - val_loss: 0.4977 - val_acc: 0.7549\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.4781 - acc: 0.7781 - val_loss: 0.4816 - val_acc: 0.7887\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 40s 216ms/step - loss: 0.4662 - acc: 0.7852 - val_loss: 0.5292 - val_acc: 0.7418\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.4634 - acc: 0.7805 - val_loss: 0.4793 - val_acc: 0.7767\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8f3e47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4902481406927109"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_aug = history.history['acc']\n",
    "val_acc_aug = history.history['val_acc']\n",
    "loss_aug = history.history['loss']\n",
    "val_loss_aug = history.history['val_loss']\n",
    "\n",
    "\n",
    "# MEAN OF VALIDATION LOSS:\n",
    "loss_mean_aug = np.mean(val_loss_aug)\n",
    "loss_mean_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36c792d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8050109148025513,\n",
       " 0.7549019455909729,\n",
       " 0.7886710166931152,\n",
       " 0.741830050945282,\n",
       " 0.7766884565353394]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSPECTION:\n",
    "val_acc_aug[5:10]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e172dd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734204769134522"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEAN OF ACCURACY:\n",
    "acc_mean_aug = np.mean(val_acc_aug[5:10])\n",
    "acc_mean_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019c568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
